2026-01-08 16:28:35 - INFO     - ================================================================================
2026-01-08 16:28:35 - INFO     - Adaptive IR System - Training
2026-01-08 16:28:35 - INFO     - ================================================================================
2026-01-08 16:28:35 - INFO     - Random seed: 42
2026-01-08 16:28:35 - WARNING  - CUDA not available, using CPU
2026-01-08 16:28:35 - INFO     - Device: cpu
2026-01-08 16:28:35 - INFO     - Loading datasets...
2026-01-08 16:28:35 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-08 16:28:35 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-08 16:28:35 - INFO     - Available splits: train, valid, test
2026-01-08 16:28:35 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-08 16:29:29 - INFO     - Loaded train split: 271345 queries
2026-01-08 16:29:29 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-08 16:29:29 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-08 16:29:29 - INFO     - Available splits: train, valid, test
2026-01-08 16:29:29 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-08 16:29:33 - INFO     - Loaded valid split: 20000 queries
2026-01-08 16:29:33 - INFO     - Train queries: 271345
2026-01-08 16:29:33 - INFO     - Val queries: 20000
2026-01-08 16:29:33 - INFO     - Initializing search engine...
2026-01-08 16:37:44 - INFO     - ================================================================================
2026-01-08 16:37:44 - INFO     - Adaptive IR System - Training
2026-01-08 16:37:44 - INFO     - ================================================================================
2026-01-08 16:37:44 - INFO     - Random seed: 42
2026-01-08 16:37:44 - WARNING  - CUDA not available, using CPU
2026-01-08 16:37:44 - INFO     - Device: cpu
2026-01-08 16:37:44 - INFO     - Loading datasets...
2026-01-08 16:37:44 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-08 16:37:44 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-08 16:37:44 - INFO     - Available splits: train, valid, test
2026-01-08 16:37:44 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-08 16:38:35 - INFO     - Loaded train split: 271345 queries
2026-01-08 16:38:35 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-08 16:38:35 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-08 16:38:35 - INFO     - Available splits: train, valid, test
2026-01-08 16:38:35 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-08 16:38:38 - INFO     - Loaded valid split: 20000 queries
2026-01-08 16:38:38 - INFO     - Train queries: 271345
2026-01-08 16:38:38 - INFO     - Val queries: 20000
2026-01-08 16:38:38 - INFO     - Initializing search engine...
2026-01-08 16:44:39 - INFO     - ================================================================================
2026-01-08 16:44:39 - INFO     - Adaptive IR System - Training
2026-01-08 16:44:39 - INFO     - ================================================================================
2026-01-08 16:44:39 - INFO     - Random seed: 42
2026-01-08 16:44:39 - WARNING  - CUDA not available, using CPU
2026-01-08 16:44:39 - INFO     - Device: cpu
2026-01-08 16:44:39 - INFO     - Loading datasets...
2026-01-08 16:44:39 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-08 16:44:39 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-08 16:44:39 - INFO     - Available splits: train, valid, test
2026-01-08 16:44:39 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-08 16:45:34 - INFO     - Loaded train split: 271345 queries
2026-01-08 16:45:34 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-08 16:45:34 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-08 16:45:34 - INFO     - Available splits: train, valid, test
2026-01-08 16:45:34 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-08 16:45:38 - INFO     - Loaded valid split: 20000 queries
2026-01-08 16:45:38 - INFO     - Train queries: 271345
2026-01-08 16:45:38 - INFO     - Val queries: 20000
2026-01-08 16:45:38 - INFO     - Initializing search engine...
2026-01-08 16:46:58 - INFO     - ================================================================================
2026-01-08 16:46:58 - INFO     - Adaptive IR System - Training
2026-01-08 16:46:58 - INFO     - ================================================================================
2026-01-08 16:46:58 - INFO     - Random seed: 42
2026-01-08 16:46:58 - WARNING  - CUDA not available, using CPU
2026-01-08 16:46:58 - INFO     - Device: cpu
2026-01-08 16:46:58 - INFO     - Loading datasets...
2026-01-08 16:46:58 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-08 16:46:58 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-08 16:46:58 - INFO     - Available splits: train, valid, test
2026-01-08 16:46:58 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-08 16:47:49 - INFO     - Loaded train split: 271345 queries
2026-01-08 16:47:49 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-08 16:47:49 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-08 16:47:49 - INFO     - Available splits: train, valid, test
2026-01-08 16:47:49 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-08 16:47:53 - INFO     - Loaded valid split: 20000 queries
2026-01-08 16:47:53 - INFO     - Train queries: 271345
2026-01-08 16:47:53 - INFO     - Val queries: 20000
2026-01-08 16:47:53 - INFO     - Initializing search engine...
2026-01-08 16:47:53 - INFO     - Using SimpleBM25Searcher for msa dataset
2026-01-08 16:51:37 - INFO     - ================================================================================
2026-01-08 16:51:37 - INFO     - Adaptive IR System - Training
2026-01-08 16:51:37 - INFO     - ================================================================================
2026-01-08 16:51:37 - INFO     - Random seed: 42
2026-01-08 16:51:37 - WARNING  - CUDA not available, using CPU
2026-01-08 16:51:37 - INFO     - Device: cpu
2026-01-08 16:51:37 - INFO     - Loading datasets...
2026-01-08 16:51:37 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-08 16:51:37 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-08 16:51:37 - INFO     - Available splits: train, valid, test
2026-01-08 16:51:37 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-08 16:52:29 - INFO     - Loaded train split: 271345 queries
2026-01-08 16:52:29 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-08 16:52:29 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-08 16:52:29 - INFO     - Available splits: train, valid, test
2026-01-08 16:52:29 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-08 16:52:33 - INFO     - Loaded valid split: 20000 queries
2026-01-08 16:52:33 - INFO     - Train queries: 271345
2026-01-08 16:52:33 - INFO     - Val queries: 20000
2026-01-08 16:52:33 - INFO     - Initializing search engine...
2026-01-08 16:52:33 - INFO     - Using SimpleBM25Searcher for msa dataset
2026-01-08 16:52:33 - INFO     - Building BM25 index from corpus...
2026-01-08 16:52:35 - INFO     - Indexing 468491 relevant documents...
2026-01-08 16:52:38 - INFO     - BM25 index built with 468491 documents
2026-01-08 16:52:38 - INFO     - Search engine: SimpleBM25 (legacy dataset)
2026-01-08 16:52:38 - INFO     - Building pipeline...
2026-01-08 16:52:38 - INFO     - Loading embeddings from D_cbow_pdw_8B.pkl...
2026-01-08 16:53:28 - INFO     - Loaded 374,557 words, dim=500
2026-01-08 16:53:28 - INFO     - Loaded legacy Word2Vec embeddings from ../Query Reformulator/D_cbow_pdw_8B.pkl
2026-01-08 16:53:28 - INFO     - Initialized Candidate Term Miner
2026-01-08 16:53:28 - INFO     - Initialized RL Agent with 2,233,091 parameters
2026-01-08 16:53:28 - INFO     - Initialized RRF Fusion (k=60)
2026-01-08 16:53:59 - INFO     - Initialized BERT Re-ranker
2026-01-08 16:53:59 - INFO     - Pipeline initialized successfully
2026-01-08 16:53:59 - INFO     - Initializing training loop...
2026-01-08 16:53:59 - INFO     - Initialized RL Training Loop
2026-01-08 16:53:59 - INFO     - Starting training...
2026-01-08 16:53:59 - INFO     - Epochs: 50
2026-01-08 16:53:59 - INFO     - Batch size: 32
2026-01-08 16:53:59 - INFO     - Episodes per update: 128
2026-01-08 16:53:59 - INFO     - --------------------------------------------------------------------------------
2026-01-08 16:53:59 - INFO     - Starting training...
2026-01-08 16:53:59 - INFO     - Computing baseline metrics (no RL)...
2026-01-08 16:54:01 - ERROR    - Training failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/root/nltk_data'
    - '/root/miniconda3/envs/myenv/nltk_data'
    - '/root/miniconda3/envs/myenv/share/nltk_data'
    - '/root/miniconda3/envs/myenv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************
Traceback (most recent call last):
  File "/mnt/d/duc/hust/web mining/project/adaptive-ir-system/train.py", line 262, in main
    training_loop.train()
  File "/mnt/d/duc/hust/web mining/project/adaptive-ir-system/src/training/train_rl.py", line 434, in train
    train_metrics = self.train_epoch(epoch)
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/duc/hust/web mining/project/adaptive-ir-system/src/training/train_rl.py", line 355, in train_epoch
    trajectory, total_reward = self.collect_episode(query, qrels)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/duc/hust/web mining/project/adaptive-ir-system/src/training/train_rl.py", line 188, in collect_episode
    result_before = self.pipeline.search(query, top_k=100)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/duc/hust/web mining/project/adaptive-ir-system/src/pipeline/adaptive_pipeline.py", line 325, in search
    candidates = self.mine_candidates(query)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/duc/hust/web mining/project/adaptive-ir-system/src/pipeline/adaptive_pipeline.py", line 142, in mine_candidates
    candidates = self.candidate_miner.extract_candidates(query, documents, scores)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/duc/hust/web mining/project/adaptive-ir-system/src/candidate_mining/term_miner.py", line 80, in extract_candidates
    query_tokens = set(self._tokenize(query))
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/d/duc/hust/web mining/project/adaptive-ir-system/src/candidate_mining/term_miner.py", line 127, in _tokenize
    tokens = word_tokenize(text)
             ^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/myenv/lib/python3.11/site-packages/nltk/tokenize/__init__.py", line 142, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/myenv/lib/python3.11/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/myenv/lib/python3.11/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/myenv/lib/python3.11/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
  File "/root/miniconda3/envs/myenv/lib/python3.11/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/myenv/lib/python3.11/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/root/nltk_data'
    - '/root/miniconda3/envs/myenv/nltk_data'
    - '/root/miniconda3/envs/myenv/share/nltk_data'
    - '/root/miniconda3/envs/myenv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

2026-01-28 00:57:35 - INFO     - ================================================================================
2026-01-28 00:57:35 - INFO     - Adaptive IR System - Training
2026-01-28 00:57:35 - INFO     - ================================================================================
2026-01-28 00:57:35 - INFO     - Random seed: 42
2026-01-28 00:57:35 - WARNING  - CUDA not available, using CPU
2026-01-28 00:57:35 - INFO     - Device: cpu
2026-01-28 00:57:35 - INFO     - Loading datasets...
2026-01-28 00:57:35 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-28 00:57:35 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-28 00:57:35 - INFO     - Available splits: train, valid, test
2026-01-28 00:57:35 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-28 00:57:50 - INFO     - Loaded train split: 271345 queries
2026-01-28 00:57:50 - INFO     - Loading legacy dataset: msa_dataset.hdf5
2026-01-28 00:57:50 - INFO     - Loaded dataset: msa_dataset.hdf5
2026-01-28 00:57:50 - INFO     - Available splits: train, valid, test
2026-01-28 00:57:50 - INFO     - Loaded corpus: msa_corpus.hdf5 (480,722 documents)
2026-01-28 00:57:51 - INFO     - Loaded valid split: 20000 queries
2026-01-28 00:57:51 - INFO     - Train queries: 271345
2026-01-28 00:57:51 - INFO     - Val queries: 20000
2026-01-28 00:57:51 - INFO     - Initializing search engine...
2026-01-28 00:57:51 - INFO     - Using SimpleBM25Searcher for msa dataset
2026-01-28 00:57:51 - INFO     - Building BM25 index from corpus...
2026-01-28 00:57:53 - INFO     - Indexing 468491 relevant documents...
2026-01-28 00:57:55 - INFO     - BM25 index built with 468491 documents
2026-01-28 00:57:55 - INFO     - Search engine: SimpleBM25 (legacy dataset)
2026-01-28 00:57:55 - INFO     - Building pipeline...
2026-01-28 00:57:55 - INFO     - Loading embeddings from D_cbow_pdw_8B.pkl...
2026-01-28 00:57:56 - INFO     - Loaded 374,557 words, dim=500
2026-01-28 00:57:56 - INFO     - Loaded legacy Word2Vec embeddings from ../Query Reformulator/D_cbow_pdw_8B.pkl
2026-01-28 00:57:56 - INFO     - Initialized Candidate Term Miner
2026-01-28 00:57:56 - INFO     - Initialized RL Agent with 2,232,323 parameters
2026-01-28 00:57:56 - INFO     - Initialized RRF Fusion (k=60)
2026-01-28 00:58:02 - INFO     - Initialized BERT Re-ranker
2026-01-28 00:58:02 - INFO     - Pipeline initialized successfully
2026-01-28 00:58:02 - INFO     - Initializing training loop...
2026-01-28 00:58:02 - INFO     - Initialized RL Training Loop
2026-01-28 00:58:02 - INFO     - Starting training...
2026-01-28 00:58:02 - INFO     - Epochs: 50
2026-01-28 00:58:02 - INFO     - Batch size: 32
2026-01-28 00:58:02 - INFO     - Episodes per update: 128
2026-01-28 00:58:02 - INFO     - --------------------------------------------------------------------------------
2026-01-28 00:58:02 - INFO     - Starting training...
2026-01-28 00:58:02 - INFO     - Computing baseline metrics (no RL)...
2026-01-28 00:58:39 - INFO     - 
Training interrupted by user
2026-01-28 00:58:39 - INFO     - ================================================================================
2026-01-28 00:58:39 - INFO     - Training completed!
2026-01-28 00:58:39 - INFO     - ================================================================================
